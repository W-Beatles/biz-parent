<?xml version="1.0" encoding="UTF-8"?>
<!-- 从高到低 OFF、FATAL、ERROR、WARN、INFO、DEBUG、TRACE、ALL -->
<!-- 日志输出规则 根据当前 ROOT 级别，日志输出时，级别高于root默认的级别会输出 -->
<!-- scan: 配置文件发生改变就会被重新加载，默认值为true
     scanPeriod: 监测配置文件是否有修改的时间间隔，如果没有给出时间单位则默认是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。
     debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 -->
<configuration scan="true" scanPeriod="60 seconds" debug="false">
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>

    <springProperty scope="context" name="sentryEnable" source="sentry.enable" defaultValue="false"/>

    <!-- rabbitmq -->
    <springProperty scope="context" name="elkRabbitmqEnable"
                    source="elk.rabbitmq.enable" defaultValue="false"/>
    <springProperty scope="context" name="elkRabbitmqHost"
                    source="elk.rabbitmq.host" defaultValue="localhost"/>
    <springProperty scope="context" name="elkRabbitmqPort"
                    source="elk.rabbitmq.port" defaultValue="5672"/>
    <springProperty scope="context" name="elkRabbitmqUsername"
                    source="elk.rabbitmq.username" defaultValue="guest"/>
    <springProperty scope="context" name="elkRabbitmqPassword"
                    source="elk.rabbitmq.password" defaultValue="guest"/>
    <springProperty scope="context" name="elkRabbitmqVirtualHost"
                    source="elk.rabbitmq.virtual-host" defaultValue="/"/>
    <springProperty scope="context" name="elkRabbitmqExchange"
                    source="elk.rabbitmq.exchange" defaultValue="topic.loggingExchange"/>
    <springProperty scope="context" name="elkRabbitmqRoutingKey"
                    source="elk.rabbitmq.routing-key" defaultValue="logback.#"/>
    <springProperty scope="context" name="elkRabbitmqApplicationId"
                    source="elk.rabbitmq.application-id" defaultValue="undefined"/>
    <springProperty scope="context" name="elkRabbitmqConnectionName"
                    source="elk.rabbitmq.connection-name" defaultValue="undefined"/>

    <!-- kafka -->
    <springProperty scope="context" name="elkKafkaEnable"
                    source="elk.kafka.enable" defaultValue="false"/>
    <springProperty scope="context" name="elkKafkaHost"
                    source="elk.kafka.host" defaultValue="localhost"/>
    <springProperty scope="context" name="elkKafkaPort"
                    source="elk.kafka.port" defaultValue="19092"/>
    <springProperty scope="context" name="elkKafkaTopic"
                    source="elk.kafka.topic" defaultValue="logback"/>
    <springProperty scope="context" name="elkKafkaBufferMemory"
                    source="elk.kafka.bufferMemory" defaultValue="33554432"/>
    <springProperty scope="context" name="elkKafkaAcks"
                    source="elk.kafka.acks" defaultValue="1"/>
    <springProperty scope="context" name="elkKafkaLingerMs"
                    source="elk.kafka.linger-ms" defaultValue="100"/>
    <springProperty scope="context" name="elkKafkaMaxBlockMs"
                    source="elk.kafka.max-block-ms" defaultValue="60000"/>
    <springProperty scope="context" name="elkKafkaCompressionType"
                    source="elk.kafka.compression-type" defaultValue="gzip"/>
    <springProperty scope="context" name="elkKafkaRetries"
                    source="elk.kafka.retries" defaultValue="2"/>

    <!-- 自定义日志配置 -->
    <include file="src/main/resources/logback-custom-spring.xml"/>

    <!-- ConsoleAppender -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>${CONSOLE_LOG_PATTERN}</pattern>
        </encoder>
    </appender>

    <!-- SentryAppender -->
    <if condition='property("sentryEnable").contains("true")'>
        <then>
            <appender name="Sentry" class="io.sentry.logback.SentryAppender">
                <!--只记录ERROR级别及以上的日志 -->
                <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
                    <level>ERROR</level>
                </filter>
            </appender>
        </then>
    </if>

    <!-- AmqpAppender -->
    <if condition='property("elkRabbitmqEnable").contains("true")'>
        <then>
            <appender name="ELK_RABBITMQ" class="cn.waynechu.bootstarter.logger.appender.AmqpAppender">
                <layout class="cn.waynechu.bootstarter.logger.layout.RabbitmqLayout"/>

                <host>${elkRabbitmqHost}</host>
                <port>${elkRabbitmqPort}</port>
                <username>${elkRabbitmqUsername}</username>
                <password>${elkRabbitmqPassword}</password>
                <applicationId>${elkRabbitmqApplicationId}</applicationId>
                <virtualHost>${elkRabbitmqVirtualHost}</virtualHost>
                <exchangeName>${elkRabbitmqExchange}</exchangeName>
                <exchangeType>topic</exchangeType>
                <declareExchange>true</declareExchange>
                <routingKeyPattern>${elkRabbitmqRoutingKey}</routingKeyPattern>
                <autoDelete>false</autoDelete>
                <generateId>true</generateId>
                <durable>true</durable>
                <deliveryMode>PERSISTENT</deliveryMode>
                <charset>UTF-8</charset>
                <contentType>text/json</contentType>
                <connectionName>${elkRabbitmqConnectionName}</connectionName>
            </appender>
        </then>
    </if>

    <!-- KafkaAppender -->
    <if condition='property("elkKafkaEnable").contains("true")'>
        <then>
            <appender name="ELK_KAFKA" class="com.github.danielwegener.logback.kafka.KafkaAppender">
                <encoder class="ch.qos.logback.core.encoder.LayoutWrappingEncoder">
                    <layout class="cn.waynechu.bootstarter.logger.layout.RabbitmqLayout"/>
                </encoder>
                <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
                    <level>INFO</level>
                </filter>

                <topic>${elkKafkaTopic}</topic>
                <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy"/>
                <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"/>
                <!-- Optional parameter to use a fixed partition -->
                <!-- <partition>0</partition> -->
                <!-- Optional parameter to include log timestamps into the kafka message -->
                <!-- <appendTimestamp>true</appendTimestamp> -->
                <!-- each <producerConfig> translates to regular kafka-client config (format: key=value) -->
                <!-- producer configs are documented here: https://kafka.apache.org/documentation.html#newproducerconfigs -->
                <!-- bootstrap.servers is the only mandatory producerConfig -->
                <producerConfig>bootstrap.servers=${elkKafkaHost}:${elkKafkaPort}</producerConfig>
                <producerConfig>buffer.memory=${elkKafkaBufferMemory}</producerConfig>
                <producerConfig>acks=${elkKafkaAcks}</producerConfig>
                <producerConfig>linger.ms=${elkKafkaLingerMs}</producerConfig>
                <producerConfig>max.block.ms=${elkKafkaMaxBlockMs}</producerConfig>
                <producerConfig>compression.type=${elkKafkaCompressionType}</producerConfig>
                <producerConfig>retries=${elkKafkaRetries}</producerConfig>
            </appender>
        </then>
    </if>

    <root level="info">
        <appender-ref ref="CONSOLE"/>
        <if condition='property("sentryEnable").contains("true")'>
            <then>
                <appender-ref ref="Sentry"/>
            </then>
        </if>
        <if condition='property("elkRabbitmqEnable").contains("true")'>
            <then>
                <appender-ref ref="ELK_RABBITMQ"/>
            </then>
        </if>
        <if condition='property("elkKafkaEnable").contains("true")'>
            <then>
                <appender-ref ref="ELK_KAFKA"/>
            </then>
        </if>
    </root>
</configuration>